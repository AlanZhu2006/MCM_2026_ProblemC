\subsection{System Design}

\subsubsection{Conceptual Framework}

We propose a machine learning-based voting system that automatically learns optimal combination strategies from historical data, simultaneously considering multiple factors (age, professional dancer, industry, region) that influence elimination outcomes. The system adapts to different season characteristics and learns patterns that may not be captured by fixed mathematical methods.

\subsubsection{Feature Space Construction}

For each contestant $i$ at week $t$, we construct a 12-dimensional feature vector $\mathbf{x}_i^{(t)} \in \mathbb{R}^{12}$ encoding normalized judge scores, normalized fan votes, normalized ranks, percentages, relative features, and factor features (age, industry, professional dancer, region). Feature engineering ensures comparability through normalization, completeness through comprehensive factor inclusion, and interpretability through clear feature meanings.

\subsubsection{Model Architecture}

We employ LightGBM gradient boosting, learning a function $f: \mathbb{R}^{12} \rightarrow [0,1]$ that maps feature vectors to elimination probabilities:
\begin{equation}
P(\text{eliminated}_i | \mathbf{x}_i^{(t)}) = f(\mathbf{x}_i^{(t)}; \boldsymbol{\theta})
\label{eq:ml_model}
\end{equation}
where $\boldsymbol{\theta}$ denotes the model parameters. The decision rule selects the contestant with highest elimination probability. The model is trained using cross-entropy loss with L2 regularization ($\lambda = 0.01$), feature subsampling (0.8), and data subsampling (0.8) to prevent overfitting.

Training employs time-series cross-validation to respect temporal ordering, with leave-one-season-out validation ensuring robust performance estimation.

\subsection{Theoretical Analysis}

\subsubsection{Fairness Properties}

The machine learning system promotes fairness by explicitly encoding fairness-relevant factors and learning optimal weights rather than imposing fixed splits. Feature importance analysis shows age accounts for 1.41\% and industry for 5.44\% of total importance, indicating balanced consideration without dominance.

\subsubsection{Excitement Properties}

The system achieves 97.99\% prediction accuracy (versus 88.96\% for traditional systems), reducing controversy while maintaining competitive intensity through continued emphasis on fan votes (62.7\% total importance).

\subsection{Historical Data Validation}

Using time-series cross-validation, the model achieves training accuracy of 99.65\%, cross-validation accuracy of 99.56\%, and prediction accuracy of 97.99\% on all 299 elimination weeks. The small training-validation gap (0.09\%) indicates minimal overfitting.

\begin{table}[H]
\centering
\caption{System Comparison: Machine Learning System versus Traditional Methods}
\begin{tabular}{lccc}
\toprule
\textbf{System} & \textbf{Accuracy} & \textbf{Correct/Total} & \textbf{Improvement} \\
\midrule
Traditional (Rank/Percent) & 88.96\% & 266/299 & Baseline \\
New ML System & 97.99\% & 293/299 & +9.03\% \\
\bottomrule
\end{tabular}
\label{tab:system_comparison}
\end{table}

Feature importance analysis reveals that fan-related features account for 62.7\% of total importance, while judge-related features account for 30.4\%. Top features include fan votes normalized (23.99\%), fan relative (15.52\%), fan rank normalized (14.72\%), judge percent (10.89\%), and fan percent (8.47\%).

\subsection{Implementation Recommendations}

Deployment should proceed in phases: data preparation and system integration (2--3 months), pilot testing on 1--2 seasons (6--12 months), full deployment with continuous monitoring, and ongoing model updates. Expected outcomes include prediction accuracy above 95\%, reduced controversy, and improved audience satisfaction.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{visualizations/stage5_ml_system.png}
\caption{Machine learning system analysis showing feature importance, performance comparisons, and validation results.}
\label{fig:stage5}
\end{figure}
